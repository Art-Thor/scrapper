#!/usr/bin/env python3
"""
Quick Quality Test for FunTrivia Scraper

Tests correctness of:
- Answer extraction
- Description extraction  
- Domain/topic/difficulty mapping
- Duplicate detection

Usage: python3 tools/quality_test.py
"""

import sys
import pandas as pd
from pathlib import Path

def test_csv_quality():
    """Test quality of existing CSV files."""
    print("üß™ –ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó CSV")
    print("=" * 50)
    
    output_dir = Path("output")
    csv_files = ["multiple_choice.csv", "true_false.csv", "sound.csv"]
    
    total_questions = 0
    issues = {
        'missing_answers': 0,
        'missing_descriptions': 0,
        'unmapped_domains': 0,
        'unmapped_difficulties': 0,
        'potential_duplicates': 0
    }
    
    all_questions = []
    
    for csv_file in csv_files:
        csv_path = output_dir / csv_file
        if not csv_path.exists():
            print(f"üìÇ {csv_file}: –ù–µ –Ω–∞–π–¥–µ–Ω")
            continue
        
        df = pd.read_csv(csv_path)
        print(f"üìÑ {csv_file}: {len(df)} –≤–æ–ø—Ä–æ—Å–æ–≤")
        
        # Check missing answers
        missing_answers = df['CorrectAnswer'].isna().sum()
        issues['missing_answers'] += missing_answers
        if missing_answers > 0:
            print(f"  ‚ö†Ô∏è  {missing_answers} –≤–æ–ø—Ä–æ—Å–æ–≤ –±–µ–∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞")
        
        # Check missing descriptions
        missing_desc = df['Description'].isna().sum()
        issues['missing_descriptions'] += missing_desc
        if missing_desc > 0:
            print(f"  ‚ö†Ô∏è  {missing_desc} –≤–æ–ø—Ä–æ—Å–æ–≤ –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è")
        
        # Check domain mapping
        unique_domains = df['Domain'].unique()
        expected_domains = ['Nature', 'Science', 'Geography', 'Culture', 'Sports', 'History', 'Religion', 'Education']
        unmapped_domains = [d for d in unique_domains if d not in expected_domains]
        if unmapped_domains:
            print(f"  ‚ö†Ô∏è  –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –¥–æ–º–µ–Ω—ã: {unmapped_domains}")
            issues['unmapped_domains'] += len(unmapped_domains)
        
        # Check difficulty mapping
        unique_difficulties = df['Difficulty'].unique()
        expected_difficulties = ['Easy', 'Normal', 'Hard']
        unmapped_diff = [d for d in unique_difficulties if d not in expected_difficulties]
        if unmapped_diff:
            print(f"  ‚ö†Ô∏è  –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏: {unmapped_diff}")
            issues['unmapped_difficulties'] += len(unmapped_diff)
        
        # Collect for duplicate analysis
        for _, row in df.iterrows():
            all_questions.append({
                'question': str(row.get('Question', '')).strip().lower(),
                'answer': str(row.get('CorrectAnswer', '')).strip().lower(),
                'file': csv_file
            })
        
        total_questions += len(df)
    
    # Duplicate detection
    seen_signatures = set()
    for q in all_questions:
        signature = f"{q['question']}|{q['answer']}"
        if signature in seen_signatures:
            issues['potential_duplicates'] += 1
        seen_signatures.add(signature)
    
    # Summary
    print(f"\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"  –í—Å–µ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {total_questions}")
    print(f"  –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã: {issues['potential_duplicates']}")
    print(f"  –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã: {issues['missing_answers']}")
    print(f"  –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è: {issues['missing_descriptions']}")
    print(f"  –ü—Ä–æ–±–ª–µ–º—ã –º–∞–ø–ø–∏–Ω–≥–∞: {issues['unmapped_domains'] + issues['unmapped_difficulties']}")
    
    # Quality score
    quality_score = 100
    if total_questions > 0:
        quality_score -= (issues['missing_answers'] / total_questions) * 30
        quality_score -= (issues['missing_descriptions'] / total_questions) * 20
        quality_score -= (issues['potential_duplicates'] / total_questions) * 25
        quality_score -= ((issues['unmapped_domains'] + issues['unmapped_difficulties']) / total_questions) * 25
    
    quality_score = max(0, quality_score)
    
    print(f"\nüéØ –û–¶–ï–ù–ö–ê –ö–ê–ß–ï–°–¢–í–ê: {quality_score:.1f}/100")
    
    if quality_score >= 90:
        print("‚úÖ –û–¢–õ–ò–ß–ù–û–ï –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö!")
    elif quality_score >= 75:
        print("üü° –•–û–†–û–®–ï–ï –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö")
    elif quality_score >= 60:
        print("üü† –ü–†–ò–ï–ú–õ–ï–ú–û–ï –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö")
    else:
        print("üî¥ –¢–†–ï–ë–£–ï–¢–°–Ø —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞")
    
    return issues, quality_score

def test_sample_extraction():
    """Test extraction on a small sample."""
    print(f"\nüî¨ –¢–ï–°–¢ –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –î–ê–ù–ù–´–•")
    print("=" * 50)
    print("–ó–∞–ø—É—Å—Ç–∏—Ç–µ: python3 src/main.py --max-questions 5 --dry-run")
    print("–î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö")

if __name__ == "__main__":
    # Test existing data quality
    issues, score = test_csv_quality()
    
    # Recommendations
    print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    if issues['missing_descriptions'] > 0:
        print(f"  - –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python3 tools/maintenance.py --fix-descriptions")
    if issues['potential_duplicates'] > 0:
        print(f"  - –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python3 tools/maintenance.py --deduplicate")
    if issues['missing_answers'] > 0:
        print(f"  - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤")
    
    print(f"\nüöÄ –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ –±–∞—Ç—á–∞:")
    print(f"  python3 tools/batch_scraper.py --batch-size 3 --parallel-jobs 1 --questions-per-batch 20") 